#!/bin/bash

print_help() {
    cat << 'EOF'
rqrun â€” resilient job submission wrapper

rqrun submits a batch job (sbatch or qsub) and automatically requeues it
when the scheduler sends a termination signal (e.g. timeout or preemption).

Usage:
  rqrun [--retries N | -r N] sbatch [sbatch options] script.sh
  rqrun [--retries N | -r N] qsub   [qsub options]   script.sh
  rqrun --help

Options:
  --retries N   Maximum number of retries (default: 3)
  -r N          Short for --retries
  --help        Print this help message

The wrapper traps scheduler signals and resubmits the job up to a configurable
retry limit:
  - Slurm/sbatch: traps SIGUSR1 (sent before termination)
  - PBS/qsub: traps SIGTERM

Note for PBS/qsub:
Because rqrun traps SIGTERM to trigger resubmission, qsub jobs will not exit
on a normal qdel. To terminate a job without requeueing, it must be killed
with:
  qdel -W force <jobid>
EOF
}

# Parse arguments
RETRY_LIMIT=${RQ_RETRY_LIMIT:-3}
ARGS=()
while [[ $# -gt 0 ]]; do
    case "$1" in
        --help)
            print_help
            exit 0
            ;;
        --retries|-r)
            if [[ -n "${2:-}" && "$2" =~ ^[0-9]+$ ]]; then
                RETRY_LIMIT="$2"
                shift
            else
                echo "rqrun: --retries / -r requires a numeric argument" >&2
                exit 1
            fi
            ;;
        *)
            ARGS+=("$1")
            ;;
    esac
    shift
done

# Require at least scheduler and script
if [[ ${#ARGS[@]} -lt 2 ]]; then
    echo "ERROR: invalid arguments" >&2
    echo "rqrun usage: rqrun [--retries N] sbatch|qsub [options] script.sh" >&2
    exit 1
fi

# Configure environment
REAL_RQRUN=$(realpath "$0")
CURRENT_RETRY=${RQ_CURRENT_RETRY:-0}
SCHEDULER="${ARGS[0]}"
OTHER_ARGS="${ARGS[@]:1:${#ARGS[@]}-2}"
USER_SCRIPT="${ARGS[-1]}"

# Block when CURRENT_RETRY exceeds RETRY_LIMIT
if [ "$CURRENT_RETRY" -gt "$RETRY_LIMIT" ]; then
    echo "[rqrun] Max retries reached" && exit 1
fi

# Resolve to absolute path for better tracing
USER_SCRIPT_ABS=$(realpath "$USER_SCRIPT" 2>/dev/null || echo "$USER_SCRIPT")
# Extract directives from the user's script
# This finds lines starting with #SBATCH or #PBS and converts them to command line flags
EXTRACTED_FLAGS=""
if [[ "$SCHEDULER" == "sbatch" ]]; then
    EXTRACTED_FLAGS=$(grep "^#SBATCH[[:space:]]" "$USER_SCRIPT" | sed 's/^#SBATCH[[:space:]]\+//' | tr '\n' ' ' | sed 's/[[:space:]]*$//')
elif [[ "$SCHEDULER" == "qsub" ]]; then
    EXTRACTED_FLAGS=$(grep "^#PBS[[:space:]]" "$USER_SCRIPT" | sed 's/^#PBS[[:space:]]\+//' | tr '\n' ' ' | sed 's/[[:space:]]*$//')
fi

# Read user script content to interpolate into submission script
USER_SCRIPT_CONTENT=$(cat "$USER_SCRIPT")

# Create a temporary submission script
USER_SCRIPT_DIR=$(dirname "$USER_SCRIPT_ABS")
SUBMISSION_SCRIPT=$(mktemp "$USER_SCRIPT_DIR/.rqrun_XXXXXX_$(basename "$USER_SCRIPT")")
SUBMISSION_SCRIPT_ABS=$(realpath "$SUBMISSION_SCRIPT" 2>/dev/null || echo "$SUBMISSION_SCRIPT")

# Write the wrapper script, then append user script content
cat << EOF > "$SUBMISSION_SCRIPT"
#!/bin/bash
# --- Auto-Injected by rqrun ---

# Log job ID if available (SLURM sets SLURM_JOB_ID, PBS sets PBS_JOBID automatically)
[ -n "\${SLURM_JOB_ID:-}" ] && echo "[rqrun] Job submitted with ID \${SLURM_JOB_ID}" >&2
[ -n "\${PBS_JOBID:-}" ] && echo "[rqrun] Job submitted with ID \${PBS_JOBID}" >&2

# Read environment variables set by the scheduler
CURRENT_RETRY=\${RQ_CURRENT_RETRY:-0}
RETRY_LIMIT=\${RQ_RETRY_LIMIT:-3}
# Flag to track if resubmission happened
RESUBMITTED=0
# Save original working dir so resubmit runs from here even if user script changed directory
RQRUN_ORIGINAL_CWD=\$(pwd)

resubmit_logic() {
    local signal_name=\$1
    local next_retry=\$((CURRENT_RETRY + 1))
    RESUBMITTED=1

    # Check if we can resubmit before saying we're going to
    if [ \$next_retry -gt \$RETRY_LIMIT ]; then
        echo "[rqrun] Max retries reached" >&2
        exit 0
    fi
    
    echo "[rqrun] Resubmitting attempt \$((next_retry + 1))/\$((RETRY_LIMIT + 1))" >&2
    
    # Run from original job dir so the requeued job starts in the same directory
    cd "\$RQRUN_ORIGINAL_CWD" || true
    # Increment retry and call rqrun again
    # Capture the output which includes the job ID
    RESUBMIT_OUTPUT=\$(RQ_CURRENT_RETRY=\$next_retry RQ_RETRY_LIMIT=\$RETRY_LIMIT \\
    "$REAL_RQRUN" $SCHEDULER $OTHER_ARGS "$USER_SCRIPT_ABS" 2>&1)
    RESUBMIT_EXIT=\$?
    if [ \$RESUBMIT_EXIT -eq 0 ]; then
        # Extract job ID from output
        # Slurm with --parsable: "188157" or "188157.cluster" -> 188157 or 188157.cluster
        # PBS: "4725400.desched1" -> 4725400.desched1
        if [[ "$SCHEDULER" == "sbatch" ]]; then
            JOB_ID=\$(echo "\$RESUBMIT_OUTPUT" | grep -oE '^[0-9]+(\.[a-zA-Z0-9_-]+)?' | head -1)
        else
            JOB_ID=\$(echo "\$RESUBMIT_OUTPUT" | sed -n 's/^\([0-9][0-9.]*[a-zA-Z0-9_-]*\).*/\1/p')
        fi
    else
        echo "[rqrun] WARNING: Resubmission may have failed (exit code: \$RESUBMIT_EXIT)" >&2
        echo "[rqrun] Output: \$RESUBMIT_OUTPUT" >&2
    fi
    # Exit 0 so the EXIT trap triggers and cleans up the script
    exit 0
}

# Trap signals: 10 (SIGUSR1, Slurm) and TERM (PBS/Generic)
# Use explicit function call to ensure proper execution
# For SLURM: only trap SIGUSR1 (timeout signal), not TERM (manual cancellation)
# For PBS: trap TERM (timeout signal)
if [[ "$SCHEDULER" == "sbatch" ]]; then
    trap 'resubmit_logic 10' 10
else
    trap 'resubmit_logic TERM' TERM
fi

# Run the user's actual script
# Script content is interpolated at submission time, so changes to the original
# file won't affect this job
# Run user script in background and wait so the trap can fire (bash only runs traps after the current command).
set +e  # Don't exit on error, we'll handle it
echo "[rqrun] Running user script: $USER_SCRIPT_ABS (attempt \$((CURRENT_RETRY + 1))/\$((RETRY_LIMIT + 1)))" >&2

# Execute user script content in a subshell in the background
# This allows bash to process signals via 'wait' while the script runs
(
$(printf '%s\n' "$USER_SCRIPT_CONTENT")
) &
USER_SCRIPT_PID=\$!

# Wait for the background process - 'wait' is interruptible by signals
# When SIGUSR1 arrives, it will interrupt 'wait' and trigger the trap
wait \$USER_SCRIPT_PID
USER_EXIT_CODE=\$?

set -e  # Re-enable exit on error
EOF

chmod +x "$SUBMISSION_SCRIPT"

# Submit to the scheduler
EXPORT_VARS="RQ_CURRENT_RETRY=$CURRENT_RETRY,RQ_RETRY_LIMIT=$RETRY_LIMIT"

if [[ "$SCHEDULER" == "sbatch" ]]; then
    # Capture stdout (job ID) separately from stderr
    # --parsable outputs job ID to stdout only, errors go to stderr
    # Use process substitution to capture stderr while keeping stdout clean
    JOB_ERROR_FILE=$(mktemp)
    JOB_OUTPUT=$(sbatch --parsable --open-mode=append --signal=B:10@60 \
        $OTHER_ARGS $EXTRACTED_FLAGS \
        --export=ALL,$EXPORT_VARS \
        "$SUBMISSION_SCRIPT" 2>"$JOB_ERROR_FILE")
    JOB_EXIT=$?
    JOB_ERROR=$(cat "$JOB_ERROR_FILE" 2>/dev/null || true)
    rm -f "$JOB_ERROR_FILE"
elif [[ "$SCHEDULER" == "qsub" ]]; then
    # For qsub, capture both stdout and stderr as job ID may be in either
    JOB_OUTPUT=$(qsub $OTHER_ARGS $EXTRACTED_FLAGS \
        -v "$EXPORT_VARS" -k oe \
        "$SUBMISSION_SCRIPT" 2>&1)
    JOB_EXIT=$?
    JOB_ERROR=""
fi

if [ $JOB_EXIT -ne 0 ]; then
    [ -n "$JOB_ERROR" ] && echo "$JOB_ERROR" >&2
    [ -n "$JOB_OUTPUT" ] && echo "$JOB_OUTPUT" >&2
    rm -f "$SUBMISSION_SCRIPT"
    exit $JOB_EXIT
fi

echo "$JOB_OUTPUT"
rm -f "$SUBMISSION_SCRIPT"
